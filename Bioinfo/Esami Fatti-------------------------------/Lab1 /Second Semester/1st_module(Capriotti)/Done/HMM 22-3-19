Given the sequence i find a way to understand the model behind it.

PROBABILITY
P(s|M)=sum in  path P(s,pi|M)

FORWARD ALG
-recurrence: sum over all previous state(transitio * emission * prob 		of previous state)

BACKWARD
-same but backward

COMPLEXITY
-naif: O(T*N^T)
-forward O(T*N^2)

SEARCHING PATH------------------------------------------------------
-VITERBI DECODING
	-forward
	-remember most probable path
	-traceback path
-A POSTERIORI
	-forward
	-backward

HMM AND ALIGNMENT-------------------------------------------------
we create an HMM (profile of a family) on an alignment an than we use it to see how other sequence align to it.

-match  
-insertion ->return on self instead of or next match
-delition  -> next del or next ins

Using more state we can have a linear complexity

-Alignment Score
-log p(s|M)


CONFUSION MATRIX (see image)---------------------
-True Positive (TPR) (sensitivity) = tp / (tp+fn)
	-how many positive are corectly predicted
-positive prediction (PPV) (precision) = tp / (tp+fp)
	-how many positive prediction are correct

N.B.: Both can be calculated also for negative(TNR and NPV)

-Accuracy (q2) = (tp+tn) / (tp+tn+fp+fn)    
	-how many true prediction are made (be aware of unbalanced 		dataset)

-MCC: Matthews correlation coef. (Same of Pearson but for categorical data)

	-1: perfect
	- -1: totally wrong
	-0: random 

	MCC= [(tp*tn)-(fp*fn)] \ sqrt[(tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)]

-ROC Curve (scan distribution of signal) (see on !!!wikipedia!!!)
	-True P rate X False P rate on a graph (1 X 1)
	-the area under the curve:
		0.5 random
		1 perfect
		0 opposite







